{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Descomenten si todavía no instalaron el cliente\n",
    "# !pip install --upgrade watson-developer-cloud\n",
    "# !pip install --upgrade watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando el Dataset\n",
    "Importamos el dataset de review de películas que utilizamos para la entrega número 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "# Acá deben completar con la dirección donde tienen el dataset de películas que usamos para la entrega 5\n",
    "moviedir = r'./Entregas Resueltas/Entrega 5/dataset/movie_reviews' \n",
    "movie_reviews = load_files(moviedir, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que este dataset consistía de un diccionario donde la key `data` contenía el texto de la review, y la key `target` tenía un 1 si ese review fue positivo y un 0 si fue negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armando el pipeline\n",
    "Primero, antes de definir nuestro workflow de trabajo, vamos a separar en Train y Test nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    movie_reviews.data, movie_reviews.target, test_size = 0.20, stratify=movie_reviews.target, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí, vamos a definir un workflow muy simple donde primero vectorizamos el texto, aplicamos una transofrmación tf-idf y luego clasificamos con un SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "vect = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ponemos estos dos pasos adentro de un único objeto, una instancia de un objeto Pipeline, al que llamamos `pipeline`. Al igual que los otros modelos, también cuenta con las funciones `fit` y `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = Pipeline([('vect',vect),('tfidf',tfidf),('clf',clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podríamos fitear y usar el modelo para predecir de manera local corriendo la siguiente linea.\n",
    "# Pero no es la idea, vamos a correrlo desde el servidor.\n",
    "pipeline2 = Pipeline([('vect',vect),('tfidf',tfidf),('clf',clf)])\n",
    "pipeline2.fit(X_train, y_train)\n",
    "pipeline2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBM Watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentá la siguiente linea para hacer la instalación\n",
    "#!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar Watson Machine Learning API es necesario crear un servicio desde:\n",
    "https://console.bluemix.net/catalog/services/machine-learning.\n",
    "\n",
    "Una vez creado ir a la lista de la izquierda a `Service Credentials` y crear nuevas credenciales. \n",
    "\n",
    "Para ver las credenciales hay que tocar en `View Credentials`. \n",
    "De allí copiar los datos necesarios para completar el código de la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials={\n",
    "# Copien y peguen sus credenciales\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los datos del modelo a publicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {client.repository.ModelMetaNames.AUTHOR_NAME: \"Yo\", \n",
    "               client.repository.ModelMetaNames.NAME: \"Reviews classification nuevo\",\n",
    "               client.repository.DefinitionMetaNames.RUNTIME_NAME: 'python',\n",
    "               client.repository.DefinitionMetaNames.RUNTIME_VERSION: '3.6'}\n",
    "\n",
    "# Si quieren usar tensorflow, pueden especificar la versión como:\n",
    "#client.repository.DefinitionMetaNames.NAME: 'my_training_definition',\n",
    "#client.repository.DefinitionMetaNames.FRAMEWORK_NAME: 'tensorflow',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subimos el modelo a la nube con `client.repository.store_model`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_model = client.repository.store_model(model=pipeline, \n",
    "                                                meta_props=model_props, \n",
    "                                                training_data=X_train, \n",
    "                                                training_target=y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el uid del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos el id con el cual nos vamos a referir al modelo\n",
    "published_model_uid = client.repository.get_model_uid(published_model)\n",
    "model_details = client.repository.get_details(published_model_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_details = client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos cargar el modelo a partir de su `uid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = client.repository.load(published_model_uid)\n",
    "test_predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"roc_auc score: \", roc_auc_score(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
